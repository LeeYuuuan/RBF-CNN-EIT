{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1B_L3jt3CFwUoZM3pnWCmkGNnDVPIU6NZ",
      "authorship_tag": "ABX9TyOUs3+PYmnCI9Dqc1UiJECT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeYuuuan/RBF-CNN-EIT/blob/main/CNN_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Rjgi6uPVlnPG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset,DataLoader,Dataset\n",
        "from torch.autograd import Variable \n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(r\"/content/drive/MyDrive/Colab Notebooks/EIT/EITDeepLearning\")\n",
        "sys.path.append(r\"/content/drive/MyDrive/Colab Notebooks/EIT/EITDeepLearning/data\")\n",
        "import torch_rbf as rbf"
      ],
      "metadata": {
        "id": "_if3RTR-7H2g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "pQeyGpF4l2tB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomEITDataSet(Dataset):\n",
        "    \"\"\"EIT simulation dataset\"\"\"\n",
        "    def __init__(self, dataset_type):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dfir: Directory with all the data.\n",
        "        \"\"\"  \n",
        "        dic_path = \"/content/drive/MyDrive/Colab Notebooks/EIT/EITDeepLearning/data/\"\n",
        "\n",
        "        # load the .csv simulation data \n",
        "        voltage_data = np.loadtxt(dic_path + 'datacsv1.csv', delimiter=';', dtype=np.float32)\n",
        "        label = np.loadtxt(dic_path + 'datacsv.csv', delimiter=';', dtype=np.float32)\n",
        "\n",
        "        # split train/test dataset\n",
        "        X_train_raw, X_test_raw, y_train, y_test = train_test_split(voltage_data, label, test_size=0.2, random_state=42)\n",
        "\n",
        "        X_train = np.zeros([X_train_raw.shape[0], 1, 16, 12]) # shape: count * 1 * 16(angle) * 12(voltage)\n",
        "        X_test = np.zeros([X_test_raw.shape[0], 1, 16, 12])\n",
        "\n",
        "        for i, data_element in enumerate(X_train_raw):\n",
        "            X_train[i, 0, :, :] = X_train_raw[i].reshape(16, 12)\n",
        "        for i, data_element in enumerate(X_test_raw):\n",
        "            X_test[i, 0, :, :] = X_test_raw[i].reshape(16,12)\n",
        "\n",
        "        # return different type of data\n",
        "        if dataset_type == 'train':\n",
        "            self.x = X_train\n",
        "            self.y = y_train\n",
        "            self.len = X_train.shape[0]\n",
        "        elif dataset_type == 'test':\n",
        "            self.x = X_test\n",
        "            self.y = y_test\n",
        "            self.len = X_test.shape[0]\n",
        "        else:\n",
        "            raise ValueError\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "PGGE0nzM3RUv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNnet(torch.nn.Module):\n",
        "    def __init__(self, layer_widths, layer_centres, basis_func):\n",
        "        super(CNNnet,self).__init__()\n",
        "        self.rbf_layers = nn.ModuleList()\n",
        "        self.linear_layers = nn.ModuleList()\n",
        "        self.conv1_1 = nn.Sequential(\n",
        "            # (1, 16, 12)pytorch输入不用定义大小，因为参数过多写成nn.Conv2d(1,64,3,1，1)形式容易出错，有的参数默认了\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,#单通道\n",
        "                out_channels=64,#64通道\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1#零填充\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(64),#批量归一化\n",
        "            nn.ELU(),#ELU激活函数\n",
        "        )\n",
        "        self.conv1_2 = nn.Sequential(\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=64,\n",
        "                out_channels=64,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(64),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d(kernel_size=2)#最大池化层，核大小为2\n",
        "        )\n",
        "        self.conv2_1 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=64,\n",
        "                out_channels=128,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(128),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv2_2 = nn.Sequential(\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=128,\n",
        "                out_channels=128,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(128),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv3_1 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=128,\n",
        "                out_channels=256,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv3_2 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=256,\n",
        "                out_channels=256,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv3_3 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=256,\n",
        "                out_channels=256,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv3_4 = nn.Sequential(\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=256,\n",
        "                out_channels=256,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv4_1 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=256,\n",
        "                out_channels=512,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv4_2 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=512,\n",
        "                out_channels=512,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv4_3 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=512,\n",
        "                out_channels=512,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv4_4 = nn.Sequential(\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=512,\n",
        "                out_channels=512,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d(kernel_size=2,ceil_mode=True)#平均池化层，核大小为2，2×1经过这层变成1×0，报错，但有ceil_mode=True为向上取整，变成1×1\n",
        "        )\n",
        "        for i in range(len(layer_widths) - 1):\n",
        "            self.rbf_layers.append(rbf.RBF(layer_widths[i], layer_centres[i], basis_func))\n",
        "            self.linear_layers.append(nn.Linear(layer_centres[i], layer_widths[i + 1]))\n",
        "        self.mlp2 = torch.nn.Linear(512,576) #输出层，512是输入这层的大小，576是输出的大小\n",
        "    '''\n",
        "    前向传播\n",
        "    '''\n",
        "    def forward(self, x):\n",
        "        x = self.conv1_1(x)\n",
        "        x = self.conv1_2(x)\n",
        "        x = self.conv2_1(x)\n",
        "        x = self.conv2_2(x)\n",
        "        x = self.conv3_1(x)\n",
        "        x = self.conv3_2(x)\n",
        "        x = self.conv3_3(x)\n",
        "        x = self.conv3_4(x)\n",
        "        x = self.conv4_1(x)\n",
        "        x = self.conv4_2(x)\n",
        "        x = self.conv4_3(x)\n",
        "        x = self.conv4_4(x)\n",
        "        x = x.view(x.size(0),-1)#四维数据（数据量，通道，纵向，横向），展开为二维（数据量，只有横向）\n",
        "        for i in range(len(self.rbf_layers)):\n",
        "            x = self.rbf_layers[i](x)\n",
        "            x = self.linear_layers[i](x)\n",
        "        x = self.mlp2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "IlhgVrtC4V1w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EjXFQMd4Le5Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset.\n",
        "dataset_train = CustomEITDataSet('train')\n",
        "train_loader = DataLoader(dataset=dataset_train, batch_size=32, shuffle=True)\n",
        "\n",
        "dataset_test = CustomEITDataSet('test')  \n",
        "test_loader = DataLoader(dataset=dataset_test, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "8TuvKzc0JG0Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DoAGnqwbco-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_widths = [512] # 神经元数量\n",
        "layer_centres = [40]\n",
        "basis_func = rbf.gaussian # 初始偏置\n",
        "\n",
        "model = CNNnet(layer_widths, layer_centres, basis_func) # Model initialized\n",
        "print(model)\n",
        "model = model.float() # parameters to float.\n",
        "device = torch.device('cuda:0')\n",
        "model.to(device) # 训练数据和模型数据类型要统一，并且pytorch-gpu数据类型要变成指定类型\n",
        "\n",
        "loss_func = torch.nn.MSELoss() # loss function: MSE\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.3, momentum=0.9) # gradient descent with momentum\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-ZxIymvVKNRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "下面矩阵存放训练过程中损失函数等数据\n",
        "'''\n",
        "loss_count = []\n",
        "iter_loss = []\n",
        "batch_loss = []\n",
        "test_loss = []\n",
        "epochs=100 #轮数\n",
        "for epoch in range(epochs):\n",
        "    for i, (x, y)in enumerate(train_loader):\n",
        "        batch_x = Variable(x).to(torch.float32) # torch.Size([, 1, 16, 12])\n",
        "        batch_x = batch_x.cuda()\n",
        "        batch_y = Variable(y).to(torch.float32) # torch.Size([576])\n",
        "        batch_y = batch_y.cuda()\n",
        "        out = model(batch_x)        # 获取最后输出\n",
        "        loss = loss_func(out, batch_y)        # 获取损失\n",
        "        batch_loss.append(loss.cuda().data.cpu().numpy())    # 使用优化器优化损失\n",
        "        opt.zero_grad()  # 清空上一步残余更新参数值\n",
        "        loss.backward() # 误差反向传播，计算参数更新值\n",
        "        opt.step() # 将参数更新值施加到net的parmeters上\n",
        "        '''\n",
        "        每20个数据显示一次训练集均方误差\n",
        "        '''\n",
        "        if i%20 == 0:\n",
        "            loss_count.append(loss)\n",
        "            print('train MSE {}:\\t'.format(i), loss.item())\n",
        "            # torch.save(model, '/content/drive/MyDrive/Colab Notebooks/EIT/EITDeepLearning/model')\n",
        "\n",
        "    for a,b in test_loader:\n",
        "        test_x = Variable(a).to(torch.float32)\n",
        "        test_x = test_x.cuda()\n",
        "        test_y = Variable(b).to(torch.float32)\n",
        "        test_y = test_y.cuda()\n",
        "        out = model(test_x)\n",
        "        loss = loss_func(out, test_y)\n",
        "        test_loss.append(loss.cuda().data.cpu().numpy())\n",
        "        '''\n",
        "        每轮示一次训练集均方误差\n",
        "        '''\n",
        "        print('test MSE {}:\\t'.format(epoch+1), loss.item())\n",
        "        break\n",
        "    iter_loss.append(np.average(np.array(batch_loss)))\n",
        "\n",
        "'''\n",
        "绘制测试集 轮数与均方误差图像\n",
        "'''\n",
        "x = np.arange(epochs)\n",
        "y = np.array(iter_loss)\n",
        "plt.plot(x, y)\n",
        "plt.title('pic')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RouIM_T8Mhz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(test_loader)\n",
        "vol, re = next(dataiter)"
      ],
      "metadata": {
        "id": "x6J_ZMxXKOvw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre = model.forward(Variable(vol).to(torch.float32).cuda())"
      ],
      "metadata": {
        "id": "vxD4IGwhc1kp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--L5EvJGeaHI",
        "outputId": "0c44205d-40a9-48d6-f028-7b6c178cc27a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.3700, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.6725, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.4250, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.2325, 0.7000, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.2050, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.6725,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.2875,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.2325, 0.6450,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1775,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
              "        0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(pre[0].cpu() - re[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex4jnk_seTjW",
        "outputId": "daa456f6-fd45-478c-9d2f-731e5f8a8b88"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0311, grad_fn=<MaxBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(re, 're.pt')\n",
        "torch.save(pre, 'pre.pt')"
      ],
      "metadata": {
        "id": "0wVIlVsVeW-m"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}